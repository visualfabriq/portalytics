{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost \n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from vf_portalytics.model import PredictionModel\n",
    "from vf_portalytics.tool import squared_error_objective_with_weighting, get_categorical_features\n",
    "from vf_portalytics.transformers import get_transformer\n",
    "from vf_portalytics.multi_model import MultiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset(n_samples, n_features, n_informative, **kwargs):\n",
    "    x, y = make_regression(\n",
    "        n_samples=n_samples, \n",
    "        n_features=n_features,\n",
    "        noise=0.5,\n",
    "        n_informative=n_informative, \n",
    "        random_state=0\n",
    "    )\n",
    "    x = pd.DataFrame(x)\n",
    "    \n",
    "    x.columns = ['feature_' + str(i) for i in range(n_features)]\n",
    "    x = x.assign(**kwargs)\n",
    "    return x, pd.Series(y, name='target')\n",
    "\n",
    "\n",
    "# Generate data for 4 different categories\n",
    "# different #samples for each category but the same #features since they belong to the same dataset\n",
    "n_features = 20\n",
    "x1, y1 = make_dataset(n_samples=400, n_features=n_features, n_informative=10, category='A')\n",
    "x2, y2 = make_dataset(n_samples=150, n_features=n_features, n_informative=8, category='B')\n",
    "x3, y3 = make_dataset(n_samples=280, n_features=n_features, n_informative=7, category='C')\n",
    "x4, y4 = make_dataset(n_samples=320, n_features=n_features, n_informative=12, category='D')\n",
    "\n",
    "# combine into one dataset\n",
    "total_x = pd.concat([x1, x2, x3, x4], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "total_y = pd.concat([y1, y2, y3, y4], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# make two random features categorical\n",
    "labels = ['g1', 'g2', 'g3']\n",
    "bins = [[],[]]\n",
    "for i in range(2):\n",
    "    bins[i] = [-np.inf, \n",
    "               total_x['feature_' + str(i)].mean() - total_x['feature_' + str(i)].std(), \n",
    "               total_x['feature_' + str(i)].mean() + total_x['feature_' + str(i)].std(), \n",
    "               total_x['feature_' + str(i)].max()]\n",
    "total_x['feature_0'] = pd.cut(total_x['feature_0'], bins=bins[0], labels=labels).astype('object')\n",
    "total_x['feature_1'] = pd.cut(total_x['feature_1'], bins=bins[1], labels=labels).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1          2          3          4\n",
      "feature_0         g2        g2         g1         g2         g3\n",
      "feature_1         g2        g2         g2         g3         g2\n",
      "feature_2  -0.587016  0.910646    1.92655    0.14966   0.192616\n",
      "feature_3   0.363698   1.71483  -0.800615  -0.351122   0.439522\n",
      "feature_4     1.0723  -1.64805   0.439618  0.0737539   0.763541\n",
      "feature_5   -1.32053  0.447212   0.447113  -0.168771 -0.0679451\n",
      "feature_6   0.499084 -0.616121    2.53691  -0.389912    2.36023\n",
      "feature_7  -0.739169 -0.397912    1.28298   0.151256  -0.100302\n",
      "feature_8    0.57095   1.68579  -0.629217   0.817049  -0.489482\n",
      "feature_9   0.312634 -0.832186    1.07982   -1.34878   0.306272\n",
      "feature_10  0.199397  0.150818    -0.2299  -0.140706  -0.716444\n",
      "feature_11 -0.177247 -0.356872   -1.30817   -1.01877   -1.00755\n",
      "feature_12 -0.379554  0.545657    1.84741   0.134662   0.566869\n",
      "feature_13 -0.155898   1.39856  -0.378736  -0.392786    2.16001\n",
      "feature_14 -0.950518  -1.72323  -0.755243    1.62882   0.302561\n",
      "feature_15 -0.503709  0.298714 -0.0836469   0.598213   -1.10907\n",
      "feature_16    1.2413  -1.64922    0.28831   0.369657  -0.966063\n",
      "feature_17 -0.463996   1.79754   0.139162  -0.346419    1.09234\n",
      "feature_18   1.94576 -0.255471   0.688946  -0.260977  -0.506274\n",
      "feature_19  0.306203   0.46629   0.180524   0.289598   0.555546\n",
      "category           A         A          A          A          A\n"
     ]
    }
   ],
   "source": [
    "# Overview of dataset\n",
    "print (total_x.head().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Declare group parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare basic parameters\n",
    "target = 'target'\n",
    "cat_feature = 'category'\n",
    "\n",
    "#feature_col_list = df.columns.drop(cat_feature)\n",
    "clusters = total_x[cat_feature].unique()\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train, validation and test set\n",
    "train_x, test_x, train_y, test_y = train_test_split(total_x, total_y, test_size=0.2, random_state=1)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=1)\n",
    "\n",
    "del x1, x2, x3, x4\n",
    "del y1, y2, y3, y4\n",
    "del total_x, total_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Selection is being done seperately and categorical features are split to nominals and ordinals,\n",
    "remaining_feat = train_x.columns # feature_info_dict['remaining_feat'] \n",
    "remaining_feat = remaining_feat.drop(cat_feature)\n",
    "\n",
    "ordinal_features = ['feature_0', 'feature_1'] # feature_info_dict['ordinal_features'] \n",
    "nominal_features = [] # feature_info_dict['nominal_features'] \n",
    "\n",
    "selected_features = {}\n",
    "for cluster in clusters:\n",
    "    selected_features[cluster] = remaining_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# space can be different for each group but let this for the future if it is needed\n",
    "space={\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2, 6, dtype = int)),\n",
    "    'subsample': hp.quniform('subsample', 0.4, 0.6, 0.05), \n",
    "    'min_child_weight': hp.quniform ('min_child_weight', 1, 20, 1),\n",
    "    'gamma' : hp.quniform('gamma', 0.7, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.4, 0.6, 0.05), \n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.001, 0.1, 0.01), \n",
    "    'transformer_nominal': hp.choice('transformer_nominal', ['TargetEncoder', 'JamesSteinEncoder']),\n",
    "    'transformer_ordinal': hp.choice('transformer_ordinal', ['OrdinalEncoder']),\n",
    "    'under_predict_weight': hp.choice('under_predict_weight', [2.0, 2.5, 3.0]),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 0.5, 1.0, 0.05), \n",
    "    'reg_lambda' : hp.quniform('reg_lambda', 1.0, 1.5, 0.05)\n",
    "}\n",
    "\n",
    "def score(params, train_x_group, train_y_group, val_x_group, val_y_group):\n",
    "        \n",
    "    categorical_features = get_categorical_features(data=train_x_group)\n",
    "\n",
    "    # preprocess ordinals\n",
    "    transformer_ordinal = get_transformer('OrdinalEncoder')\n",
    "    gp_ordinal = [feature for feature in categorical_features if feature in ordinal_features]\n",
    "    transformer_ordinal.cols = gp_ordinal\n",
    "\n",
    "    # preprocess nominals\n",
    "    transformer_nominal = get_transformer('TargetEncoder')\n",
    "    gp_nominals = [feature for feature in categorical_features if feature in nominal_features or feature not in gp_ordinal]\n",
    "    transformer_nominal.cols = gp_nominals\n",
    "    assert set(gp_nominals + gp_ordinal) == set(categorical_features)\n",
    "\n",
    "    gbm_model = xgboost.XGBRegressor(n_estimators = 1000, \n",
    "                                     objective = partial(squared_error_objective_with_weighting, \n",
    "                                                         under_predict_weight=params['under_predict_weight']), \n",
    "                                     max_depth = params['max_depth'],\n",
    "                                     subsample = params['subsample'],\n",
    "                                     min_child_weight = params['min_child_weight'],\n",
    "                                     gamma = params['gamma'],\n",
    "                                     colsample_bytree = params['colsample_bytree'],\n",
    "                                     learning_rate = params['learning_rate'],\n",
    "                                     reg_alpha = params['reg_alpha'],\n",
    "                                     reg_lambda = params['reg_lambda'],                                    \n",
    "                                     n_jobs = 8,\n",
    "                                     seed = 1234,\n",
    "                                     silent=True)\n",
    "    \n",
    "    pipeline = Pipeline([('transformer_ordinal', transformer_ordinal), \n",
    "                     ('transformer_nominal', transformer_nominal), \n",
    "                     ('estimator', gbm_model)])\n",
    "\n",
    "    pipe_trf = Pipeline(pipeline.steps[:-1])\n",
    "    pipe_trf = pipe_trf.fit(train_x_group, train_y_group)\n",
    "    eval_set = [(pipe_trf.transform(train_x_group), train_y_group), (pipe_trf.transform(val_x_group), val_y_group)]\n",
    "    eval_metric = [\"mae\"]\n",
    "\n",
    "    pipeline.fit(train_x_group, train_y_group, \n",
    "                 estimator__early_stopping_rounds=30, \n",
    "                 estimator__eval_set=eval_set, \n",
    "                 estimator__eval_metric=eval_metric,\n",
    "                 estimator__verbose=False)\n",
    "    \n",
    "    n_estimators = pipeline.named_steps['estimator'].best_iteration\n",
    "    params['n_estimators'] = n_estimators\n",
    "    evals_result = pipeline.named_steps['estimator'].evals_result()\n",
    "    loss = evals_result['validation_1'][eval_metric[0]][n_estimators]\n",
    "    \n",
    "    return {'loss' : loss, 'status' : STATUS_OK, 'n_estimators': n_estimators}\n",
    "\n",
    "\n",
    "def optimize(space, train_x_group, train_y_group, val_x_group, val_y_group, gp_key):\n",
    "    trials = Trials()\n",
    "    fmin_objective = partial(score, train_x_group=train_x_group, train_y_group=train_y_group, \n",
    "                             val_x_group=val_x_group, val_y_group=val_y_group)\n",
    "\n",
    "    best = fmin(fn=fmin_objective, \n",
    "                space=space, \n",
    "                algo=tpe.suggest, \n",
    "                max_evals=20, \n",
    "                trials=trials\n",
    "               )\n",
    "    return space_eval(space, best), trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking A ...\n",
      "100%|██████████| 20/20 [00:22<00:00,  1.13s/trial, best loss: 52.399776]\n",
      "Checking B ...\n",
      "100%|██████████| 20/20 [00:06<00:00,  2.90trial/s, best loss: 61.088593]\n",
      "Checking C ...\n",
      "100%|██████████| 20/20 [00:17<00:00,  1.14trial/s, best loss: 50.475033]\n",
      "Checking D ...\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.68trial/s, best loss: 60.802723]\n"
     ]
    }
   ],
   "source": [
    "groups = train_x.groupby(cat_feature)\n",
    "params = {}\n",
    "for gp_key, group in groups:\n",
    "    print('Checking ' + gp_key + ' ...')\n",
    "    # keep only the most improtant features\n",
    "    train_x_group = group[list(selected_features[gp_key])]\n",
    "    train_y_group = train_y[train_x_group.index]\n",
    "    # validation set\n",
    "    val_x_group = val_x[val_x[cat_feature]==gp_key]\n",
    "    val_x_group = val_x_group[list(selected_features[gp_key])]\n",
    "    val_y_group = val_y[val_x_group.index]\n",
    "    # find best parameters for each model-group\n",
    "    \n",
    "    best_params, trials = optimize(space, \n",
    "                                   train_x_group, train_y_group, \n",
    "                                   val_x_group, val_y_group, \n",
    "                                   gp_key)\n",
    "    params[gp_key] = best_params\n",
    "    params[gp_key]['n_estimators'] = trials.best_trial['result']['n_estimators']\n",
    "    \n",
    "# in the end we keep params; a dictionary with keys the group names and values dictionaries of the selected hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate train and validation set before training the model\n",
    "train_x = pd.concat([train_x, val_x], ignore_index=True)\n",
    "train_y = pd.concat([train_y, val_y], ignore_index=True)\n",
    "del val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for A trained\n",
      "Model for B trained\n",
      "Model for C trained\n",
      "Model for D trained\n"
     ]
    }
   ],
   "source": [
    "# Initiliaze model\n",
    "model = MultiModel(group_col=cat_feature, clusters=clusters, params=params, selected_features=selected_features,\n",
    "                  nominals=nominal_features, ordinals=ordinal_features)\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "pred_train_y = model.predict(train_x)\n",
    "pred_test_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance 0.99\n",
      "Validation performance 0.8\n"
     ]
    }
   ],
   "source": [
    "print('Train performance {}'.format(round(r2_score(train_y, pred_train_y), 2)))\n",
    "print('Validation performance {}'.format(round(r2_score(test_y, pred_test_y), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Train final model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with the whole dataset! \n",
    "# Initiliaze model\n",
    "# combine into one dataset\n",
    "total_x = pd.concat([train_x, test_x], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "total_y = pd.concat([train_y, test_y], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "del train_x, train_y, test_x, test_y\n",
    "\n",
    "# Initiliaze model\n",
    "model = MultiModel(group_col=cat_feature, clusters=clusters, params=params,\n",
    "                   selected_features=selected_features, nominals=nominal_features, ordinals=ordinal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: must use one_hot_encode=False to prevent one-hot encoding of categorical features in input data\n",
    "prediction_model = PredictionModel(\"multi_model\", path='./exported_models', one_hot_encode=False)\n",
    "prediction_model.model = model\n",
    "# save feature names (no strictly since all the preprocessing is made being made in the pipeline)\n",
    "prediction_model.features = {key: [] for key in total_x.columns}\n",
    "prediction_model.target = {target: []}\n",
    "\n",
    "prediction_model.ordered_column_list = sorted(total_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for A trained\n",
      "Model for B trained\n",
      "Model for C trained\n",
      "Model for D trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiModel(clusters=array(['A', 'B', 'C', 'D'], dtype=object),\n",
       "      group_col='category', nominals=[],\n",
       "      ordinals=['feature_0', 'feature_1'],\n",
       "      params={'A': {'n_estimators': 266, 'reg_alpha': 0.9, 'under_predict_weight': 3.0, 'colsample_bytree': 0.55, 'learning_rate': 0.07, 'min_child_weight': 10.0, 'transformer_ordinal': 'OrdinalEncoder', 'subsample': 0.55, 'reg_lambda': 1.05, 'transformer_nominal': 'TargetEncoder', 'max_depth': 2, 'gamma'...bda': 1.4500000000000002, 'transformer_nominal': 'JamesSteinEncoder', 'max_depth': 2, 'gamma': 0.9}},\n",
       "      selected_features={'A': Index([u'feature_0', u'feature_1', u'feature_2', u'feature_3', u'feature_4',\n",
       "       u'feature_5', u'feature_6', u'feature_7', u'feature_8', u'feature_9',\n",
       "       u'feature_10', u'feature_11', u'feature_12', u'feature_13',\n",
       "       u'feature_14', u'feature_15', u'feature_16', u'f...ture_15', u'feature_16', u'feature_17',\n",
       "       u'feature_18', u'feature_19'],\n",
       "      dtype='object')})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model.model.fit(total_x, total_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
