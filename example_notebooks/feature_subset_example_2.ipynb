{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from numpy.random import randint\n",
    "import random\n",
    "import itertools \n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from vf_portalytics.model import PredictionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(random_state, n_informative, collumn_names, **kwargs):\n",
    "    x, y = make_regression(\n",
    "        \n",
    "        n_samples=1000, \n",
    "        n_features=5,\n",
    "        noise=0 if random_state == 1 else 10,\n",
    "        bias=10 if random_state == 1 else 1000,\n",
    "        n_informative=min(n_informative, 5), \n",
    "        random_state=random_state\n",
    "    )\n",
    "    x = pd.DataFrame(x)\n",
    "    x.columns = [name for name in collumn_names]\n",
    "    x = x.assign(**kwargs)\n",
    "    x['yearweek'] = randint(1, 54, len(x))\n",
    "    # pack_type 0: 'Can', 1: 'Bottle'\n",
    "    x['pack_type'] = random.choices([0, 1], k=len(x))\n",
    "    \n",
    "    return x, pd.Series(y)\n",
    "\n",
    "def make_dict():\n",
    "    \"\"\"Creates a dictionary with keys all the combinations between the weeks of the year and the pack types\"\"\"\n",
    "    all_list = [list(range(1, 54)), [0, 1] ]\n",
    "    keys = list(itertools.product(*all_list))\n",
    "    values = random.choices(np.linspace(-2.5, 2.5, num=500), k=len(keys))\n",
    "    return dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data and lookup dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "collumn_names = ['price', 'promo_week_length', \n",
    "                 'yearweek',  'pack_type', 'vol_per_sku']\n",
    "\n",
    "x1, y1 = make_dataset(1, 5, collumn_names, account_banner='A', product_desc='X')\n",
    "x2, y2 = make_dataset(2, 3, collumn_names, account_banner='B', product_desc='Y')\n",
    "\n",
    "# combine into one dataset\n",
    "total_x = pd.concat([x1, x2], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "total_y = pd.concat([y1, y2], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "# Split into train and test\n",
    "train_index, test_index = train_test_split(total_x.index, random_state=5)\n",
    "train_x, train_y = total_x.loc[train_index, :], total_y.loc[train_index]\n",
    "test_x, test_y = total_x.loc[test_index, :], total_y.loc[test_index]\n",
    "\n",
    "# create dictionary \"predicted_market_volumes\" - \"lookup_dict\"\n",
    "lookup_dict = make_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): 0.9769539078156311,\n",
       " (1, 1): -2.1192384769539077,\n",
       " (2, 0): 0.5160320641282565,\n",
       " (2, 1): -2.1993987975951903,\n",
       " (3, 0): -2.3296593186372747,\n",
       " (3, 1): -1.5781563126252505,\n",
       " (4, 0): -1.3677354709418839,\n",
       " (4, 1): 2.4699398797595187,\n",
       " (5, 0): -2.2695390781563125,\n",
       " (5, 1): 2.129258517034068,\n",
       " (6, 0): -0.8466933867735471,\n",
       " (6, 1): 1.5080160320641278,\n",
       " (7, 0): -1.588176352705411,\n",
       " (7, 1): -0.6763527054108218,\n",
       " (8, 0): 1.467935871743487,\n",
       " (8, 1): 1.7284569138276549,\n",
       " (9, 0): 0.04509018036072154,\n",
       " (9, 1): -2.1993987975951903,\n",
       " (10, 0): 1.437875751503006,\n",
       " (10, 1): -0.5561122244488979,\n",
       " (11, 0): -0.18537074148296595,\n",
       " (11, 1): -2.379759519038076,\n",
       " (12, 0): 1.7885771543086166,\n",
       " (12, 1): -0.5761523046092185,\n",
       " (13, 0): 2.1593186372745485,\n",
       " (13, 1): 0.12525050100200374,\n",
       " (14, 0): 0.35571142284569124,\n",
       " (14, 1): -1.968937875751503,\n",
       " (15, 0): 0.42585170340681344,\n",
       " (15, 1): 0.876753507014028,\n",
       " (16, 0): 2.1192384769539077,\n",
       " (16, 1): 1.2975951903807612,\n",
       " (17, 0): 2.1192384769539077,\n",
       " (17, 1): -1.7384769539078158,\n",
       " (18, 0): -2.3897795591182365,\n",
       " (18, 1): 2.449899799599198,\n",
       " (19, 0): -0.8567134268537075,\n",
       " (19, 1): -0.13527054108216463,\n",
       " (20, 0): 2.079158316633267,\n",
       " (20, 1): -0.04509018036072154,\n",
       " (21, 0): 2.389779559118236,\n",
       " (21, 1): -2.4398797595190382,\n",
       " (22, 0): -0.5460921843687376,\n",
       " (22, 1): -1.5380761523046091,\n",
       " (23, 0): 0.7464929859719436,\n",
       " (23, 1): -1.8987975951903808,\n",
       " (24, 0): 0.3857715430861721,\n",
       " (24, 1): -1.5781563126252505,\n",
       " (25, 0): 1.24749498997996,\n",
       " (25, 1): 2.2494989979959916,\n",
       " (26, 0): -2.2094188376753507,\n",
       " (26, 1): -1.0671342685370742,\n",
       " (27, 0): -1.277555110220441,\n",
       " (27, 1): -1.2975951903807617,\n",
       " (28, 0): -0.6362725450901805,\n",
       " (28, 1): -1.5380761523046091,\n",
       " (29, 0): 1.347695390781563,\n",
       " (29, 1): 2.3296593186372743,\n",
       " (30, 0): -0.04509018036072154,\n",
       " (30, 1): -0.3557114228456917,\n",
       " (31, 0): -1.1072144288577155,\n",
       " (31, 1): -0.3356713426853708,\n",
       " (32, 0): 0.2955911823647295,\n",
       " (32, 1): -0.45591182364729477,\n",
       " (33, 0): 1.5681362725450896,\n",
       " (33, 1): -1.2975951903807617,\n",
       " (34, 0): -2.159318637274549,\n",
       " (34, 1): 2.0090180360721437,\n",
       " (35, 0): -1.24749498997996,\n",
       " (35, 1): 0.28557114228456904,\n",
       " (36, 0): 1.097194388777555,\n",
       " (36, 1): -0.055110220440881985,\n",
       " (37, 0): 1.1873747494989977,\n",
       " (37, 1): -1.3877755511022045,\n",
       " (38, 0): -1.688376753507014,\n",
       " (38, 1): 0.32565130260521036,\n",
       " (39, 0): -0.39579158316633256,\n",
       " (39, 1): -0.3557114228456917,\n",
       " (40, 0): 2.3597194388777556,\n",
       " (40, 1): -0.13527054108216463,\n",
       " (41, 0): 0.07515030060120242,\n",
       " (41, 1): 1.0671342685370742,\n",
       " (42, 0): 1.9589178356713424,\n",
       " (42, 1): -1.0671342685370742,\n",
       " (43, 0): -0.8967935871743489,\n",
       " (43, 1): 1.9188376753507015,\n",
       " (44, 0): -0.6963927855711423,\n",
       " (44, 1): -1.3877755511022045,\n",
       " (45, 0): 1.1372745490981964,\n",
       " (45, 1): 0.415831663326653,\n",
       " (46, 0): 0.9268537074148293,\n",
       " (46, 1): 0.05511022044088154,\n",
       " (47, 0): -1.588176352705411,\n",
       " (47, 1): 1.6983967935871744,\n",
       " (48, 0): -1.5080160320641283,\n",
       " (48, 1): 0.8266533066132262,\n",
       " (49, 0): -0.5360721442885772,\n",
       " (49, 1): 2.4899799599198396,\n",
       " (50, 0): -1.938877755511022,\n",
       " (50, 1): 2.3797595190380756,\n",
       " (51, 0): -0.2955911823647295,\n",
       " (51, 1): 0.7765531062124249,\n",
       " (52, 0): -0.04509018036072154,\n",
       " (52, 1): -1.9589178356713428,\n",
       " (53, 0): -1.24749498997996,\n",
       " (53, 1): -1.057114228456914}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "\n",
    "\n",
    "class FeatureSubsetTransform(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, group_cols=None, transformer=None):\n",
    "        \"\"\"Build a feature tranformer\"\"\"\n",
    "        self.transformer = transformer\n",
    "        self.group_cols = group_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Drop the columns that are being used to group the data and fit the transformer\"\"\"\n",
    "        x_in = X.drop([n for n in self.group_cols], axis=1)\n",
    "        self.transformer = self.transformer.fit(X=x_in[['price']])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x_in = X.drop([n for n in self.group_cols], axis=1)\n",
    "        # transform the price collumn\n",
    "        transformed_price = self.transformer.transform(X=x_in[['price']])\n",
    "        # convert data into initial format\n",
    "        transformed_price = pd.DataFrame(data=transformed_price, index=x_in.index,\n",
    "                                     columns=self.transformer.get_feature_names(x_in.columns))\n",
    "        transformed_price.drop(['1', 'price'], axis=1, inplace=True)\n",
    "        transformed_x = pd.concat([x_in, transformed_price], axis=1)\n",
    "        transformed_x[list(self.group_cols)] = X[list(self.group_cols)]\n",
    "        return transformed_x\n",
    "\n",
    "\n",
    "class FeatureSubsetModel(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, lookup_dict=None, group_cols=None, sub_models=None):\n",
    "        \"\"\"\n",
    "        Build regression model for subsets of feature rows matching particular combination of feature columns.\n",
    "        \"\"\"\n",
    "        self.lookup_dict = lookup_dict\n",
    "        self.group_cols = group_cols\n",
    "        self.sub_models = sub_models\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Partition the training data, X, into groups for each unique combination of values in\n",
    "        ``self.group_cols`` columns. For each group, train the appropriate model specified in\n",
    "        ``self.sub_models``.\n",
    "        \"\"\"\n",
    "        X['predicted_market_volume'] = itemgetter(*zip(X['yearweek'], \n",
    "                                                       X['pack_type']))(self.lookup_dict)\n",
    "        groups = X.groupby(by=list(self.group_cols))\n",
    "        \n",
    "        for gp_key, x_group in groups:\n",
    "            # Find the sub-model for this group key\n",
    "            gp_model = self.sub_models[gp_key]\n",
    "\n",
    "            # Drop the feature values for the group columns, since these are same for all rows\n",
    "            # and so don't contribute anything into the prediction.\n",
    "            x_in = x_group.drop([n for n in self.group_cols], axis=1)\n",
    "            y_in = y.loc[x_in.index]\n",
    "            \n",
    "            # Fit the submodel with subset of rows and only collumns related to price\n",
    "            gp_model = gp_model.fit(X=x_in[[col for col in x_in if col.startswith('price')]], y=y_in.values)\n",
    "            self.sub_models[gp_key] = gp_model\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Same as ``self.fit()``, but call the ``predict()`` method for each submodel and return the results.\n",
    "        \"\"\"\n",
    "        # create a new collumn by checking the lookup_dict\n",
    "        X['predicted_market_volume'] = itemgetter(*zip(X['yearweek'], \n",
    "                                                       X['pack_type']))(self.lookup_dict)\n",
    "        groups = X.groupby(by=list(self.group_cols))\n",
    "        results = []\n",
    "\n",
    "        for gp_key, x_group in groups:\n",
    "            gp_model = self.sub_models[gp_key]\n",
    "            x_in = x_group.drop([n for n in self.group_cols], axis=1)\n",
    "            \n",
    "            # predict market share only using price related data\n",
    "            predicted_market_share = gp_model.predict(X=x_in[[col for col in x_in if col.startswith('price')]])\n",
    "            predicted_market_share = pd.Series(index=x_in.index, data=predicted_market_share)\n",
    "            \n",
    "            result = predicted_market_share.mul(\n",
    "                x_group['predicted_market_volume']).mul(\n",
    "                x_group['promo_week_length']).div(\n",
    "                x_group['vol_per_sku']).clip(lower=0)\n",
    "            \n",
    "            results.append(result)\n",
    "\n",
    "        return pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "subset_cols = ('account_banner', 'product_desc')\n",
    "sub_models = {\n",
    "    ('A', 'X'): LinearRegression(),\n",
    "    ('B', 'Y'): DecisionTreeRegressor(),\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline([  \n",
    "  ('transform', FeatureSubsetTransform(group_cols=subset_cols, transformer=PolynomialFeatures(2))),\n",
    "  ('estimate', FeatureSubsetModel(lookup_dict=lookup_dict, group_cols=subset_cols, sub_models=sub_models))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create VF Model Wrapper and Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note: must use one_hot_encode=False to prevent one-hot encoding of categorical features in input data\n",
    "model_wrapper = PredictionModel(\"my_test_model\", path='/tmp', one_hot_encode=False)\n",
    "\n",
    "model_wrapper.model = pipeline\n",
    "# save feature names (no strictly since all the preprocessing is made being made in the pipeline)\n",
    "model_wrapper.features = {\n",
    "    # Grouping features\n",
    "    'account_banner': [],\n",
    "    'product_desc': [],\n",
    "    # other feaures\n",
    "    'price': [],\n",
    "    'promo_week_length': [],\n",
    "    'yearweek': [],\n",
    "    'pack_type': [],\n",
    "    'vol_per_sku': [],\n",
    "}\n",
    "model_wrapper.target = {'target': []}\n",
    "model_wrapper.ordered_column_list = sorted(model_wrapper.features.keys())\n",
    "\n",
    "model_wrapper.model.fit(train_x, train_y)\n",
    "\n",
    "model_wrapper.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Pre-Saved Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transform',\n",
       "                 FeatureSubsetTransform(group_cols=('account_banner',\n",
       "                                                    'product_desc'),\n",
       "                                        transformer=PolynomialFeatures(degree=2,\n",
       "                                                                       include_bias=True,\n",
       "                                                                       interaction_only=False,\n",
       "                                                                       order='C'))),\n",
       "                ('estimate',\n",
       "                 FeatureSubsetModel(group_cols=('account_banner',\n",
       "                                                'product_desc'),\n",
       "                                    lookup_dict={(0, 0): 1.317635270541082,\n",
       "                                                 (0, 1): 0.005010020040080221,\n",
       "                                                 (1, 0): -...\n",
       "                                                                             fit_intercept=True,\n",
       "                                                                             n_jobs=None,\n",
       "                                                                             normalize=False),\n",
       "                                                ('B', 'Y'): DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                  criterion='mse',\n",
       "                                                                                  max_depth=None,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  max_leaf_nodes=None,\n",
       "                                                                                  min_impurity_decrease=0.0,\n",
       "                                                                                  min_impurity_split=None,\n",
       "                                                                                  min_samples_leaf=1,\n",
       "                                                                                  min_samples_split=2,\n",
       "                                                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                                                  presort='deprecated',\n",
       "                                                                                  random_state=None,\n",
       "                                                                                  splitter='best')}))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't specify one_hot_encode here because it will be looked up from the pickle file\n",
    "saved_model = PredictionModel('my_test_model', path='/tmp')\n",
    "saved_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for the first group if the pipeline performs what we would like to\n",
    "groups = train_x.groupby(by=list(subset_cols))\n",
    "_, train_x = list(groups)[0]\n",
    "\n",
    "groups = test_x.groupby(by=list(subset_cols))\n",
    "_, test_x = list(groups)[0]\n",
    "\n",
    "train_y = train_y.loc[train_x.index]\n",
    "test_y = test_y.loc[test_x.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with pipeline\n",
    "pipeline_predicted = saved_model.model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that declare the group since we use only one group for the test\n",
    "test_x.drop(list(subset_cols), axis=1, inplace=True)\n",
    "train_x.drop(list(subset_cols), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# transform price collumn\n",
    "transformer = PolynomialFeatures(2)\n",
    "transformer.fit(train_x[['price']])\n",
    "\n",
    "def transform_data(data):\n",
    "    transformed_price = transformer.transform(data[['price']])\n",
    "    transformed_price = pd.DataFrame(data=transformed_price, index=data.index,\n",
    "                                         columns=transformer.get_feature_names(data.columns))\n",
    "    transformed_price.drop(['1', 'price'], axis=1, inplace=True)\n",
    "    transformed_x = pd.concat([data, transformed_price], axis=1)\n",
    "    return transformed_x\n",
    "train_transformed = transform_data(train_x)\n",
    "test_transformed = transform_data(test_x)\n",
    "\n",
    "price_collumns = [col for col in test_transformed if col.startswith('price')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict market share only using price related data\n",
    "model = LinearRegression().fit(train_transformed[price_collumns], train_y)\n",
    "\n",
    "predicted_market_share = model.predict(test_transformed[price_collumns])\n",
    "predicted_market_share = pd.Series(index=test_transformed.index, data=predicted_market_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict output\n",
    "test_x['predicted_market_volume'] = itemgetter(*zip(test_x['yearweek'], \n",
    "                                                       test_x['pack_type']))(lookup_dict)\n",
    "\n",
    "directly_predicted = predicted_market_share.mul(\n",
    "        test_x['predicted_market_volume']).mul(\n",
    "        test_x['promo_week_length']).div(\n",
    "        test_x['vol_per_sku']).clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directly_predicted</th>\n",
       "      <th>pipeline_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.512737</td>\n",
       "      <td>0.512737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1061.389376</td>\n",
       "      <td>1061.389376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.032253</td>\n",
       "      <td>0.032253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     directly_predicted  pipeline_predicted\n",
       "51             0.000000            0.000000\n",
       "417            0.512737            0.512737\n",
       "269            0.000000            0.000000\n",
       "191            0.000000            0.000000\n",
       "436            0.000000            0.000000\n",
       "..                  ...                 ...\n",
       "151         1061.389376         1061.389376\n",
       "629            0.000000            0.000000\n",
       "574            0.000000            0.000000\n",
       "886            0.032253            0.032253\n",
       "279            0.000000            0.000000\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'directly_predicted': directly_predicted, 'pipeline_predicted': pipeline_predicted})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}